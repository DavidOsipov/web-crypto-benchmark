# Методология сбора и анализа данных для проекта по бенчмаркингу Web Crypto API

**Версия документа:** 4.0-ru
**Дата:** 12.08.2025
**Аудитория:** Технические специалисты, эксперты в области статистики, веб-производительности и браузерных технологий.

## 1. Введение и цели исследования

Этот документ описывает методологию, используемую для сбора и анализа данных о производительности криптографического хеширования в современных веб-браузерах. После стратегического пересмотра основная цель проекта была переформулирована с приоритетом на **точность измерений и научную строгость**, а не на репрезентативность для среднестатистического сайта.

**Основная цель исследования** — провести высокоточный сравнительный анализ пропускной способности движков Web Crypto, чтобы ответить на следующие вопросы:

1.  **Сравнение производительности браузерных движков:** Существуют ли статистически значимые различия в производительности реализаций `SubtleCrypto.digest()` между основными браузерными движками (V8, SpiderMonkey, JavaScriptCore) в оптимизированных условиях с низким уровнем шума?
2.  **Влияние аппаратного обеспечения:** Как фундаментальные характеристики оборудования (архитектура ЦП, количество ядер, объем памяти устройства) коррелируют со скоростью хеширования при минимизации внешних шумов?
3.  **Масштабируемость алгоритмов:** Какова точная кривая масштабирования производительности для различных алгоритмов SHA при увеличении размера данных на разных платформах?

Методология разработана с учетом трех ключевых принципов: **максимальная точность**, **статистическая робастность** и **минимизация систематических ошибок (bias)**.

---

## 2. Методология измерений на стороне клиента: подход с приоритетом точности

Для достижения наших исследовательских целей архитектура на стороне клиента была полностью переработана с целью агрессивного устранения источников шума в измерениях. Данный бенчмарк является «лабораторным».

### 2.1. Среда выполнения: изоляция между источниками (Cross-Origin Isolation) — Обязательно

**Решение:** Бенчмарк развертывается исключительно на странице, которая обслуживается с заголовками `Cross-Origin-Opener-Policy: same-origin` и `Cross-Origin-Embedder-Policy: require-corp`. Бенчмарк **ОБЯЗАН** отказаться от запуска, если `window.crossOriginIsolated` имеет значение `false`.

**Обоснование:**
*   **Таймеры высокого разрешения:** Это самое критичное преимущество. Изоляция между источниками (COI) разблокирует таймеры высокой точности (`performance.now()`), уменьшая ошибку квантования измерений на порядки (с ~100 мкс до ~5 мкс или менее). Это кардинально улучшает соотношение сигнал/шум для операций, занимающих доли миллисекунды.
*   **Доступ к SharedArrayBuffer:** COI является обязательным условием для использования `SharedArrayBuffer`, который необходим для нашего протокола связи с низким уровнем помех.
*   **Стабильность процесса:** COI обеспечивает более строгую изоляцию процессов, что снижает вмешательство со стороны других вкладок браузера и системных процессов.

### 2.2. Протокол коммуникации: SharedArrayBuffer с атомарной координацией

**Решение:** Все высокочастотные данные, в частности, замеры времени для каждой группы итераций (батча), передаются из Web Worker в основной поток через `SharedArrayBuffer` (SAB).

**Обоснование:**
*   **Устранение накладных расходов на сериализацию:** Стандартный `postMessage` API включает клонирование данных, что создает нагрузку на ЦП и вносит джиттер планировщика, напрямую загрязняя измерения. SAB обеспечивает механизм передачи данных без копирования (zero-copy), делая коммуникацию практически бесшумной и не влияющей на измерения.
*   **Робастная атомарная координация:** Для обеспечения целостности данных и предотвращения состояний гонки используется **протокол с двумя атомарными счетчиками**. Worker резервирует слот для записи с помощью одного атомарного счетчика (`WR_HEAD`) и делает данные видимыми для читателей, только увеличивая второй счетчик (`COMMITTED`) *после* завершения записи. Этот паттерн «резервируй и подтверждай» (reserve-and-commit) гарантирует, что основной поток никогда не прочитает устаревшие или неполные данные.

### 2.3. Контекст выполнения: Web Worker

**Решение:** Все криптографические операции и измерения выполняются исключительно внутри выделенного Web Worker (`crypto-benchmark.worker.js`).

**Обоснование:**
*   **Отделение от основного потока:** Это предотвращает вмешательство в измерения со стороны рендеринга UI, обработки событий и сборки мусора в основном потоке.

### 2.4. Параметры тестирования

**Решение:**
*   **Алгоритмы (`algos`):** `["SHA-256", "SHA-384", "SHA-512"]`.
*   **Размеры данных (`sizes`):** `[1 КБ, 5 КБ, 10 КБ, 20 КБ, 40 КБ, 80 КБ, 100 КБ]`.

### 2.5. Минимизация систематических ошибок измерений

#### 2.5.1. Прогрев JIT-компилятора

**Решение:** Перед началом любого измерения для каждой тестовой ячейки выполняется фаза адаптивного прогрева. Эта фаза гарантирует, что JIT-компилятор (Just-In-Time) полностью оптимизировал соответствующие участки кода. Отдельный краткий прогрев также выполняется на этапе начальной калибровки.

#### 2.5.2. Предотвращение мемоизации: пул входных данных

**Решение:** Вместо хеширования одного и того же буфера данных используется пул из восьми буферов (`poolSize: 8`) со случайными данными, которые циклически сменяются. Это предотвращает мемоизацию (кеширование) результатов современными движками JS.

### 2.6. Обеспечение статистической стабильности и точности

Наша адаптивная стратегия измерений нацелена на достижение высокой статистической мощности для каждого отдельного запуска теста.

#### 2.6.1. Многофазная организация измерений

Worker выполняет трехфазный процесс для каждого полного запуска бенчмарка:
1.  **Фаза 1: Калибровка:** Выполняется быстрый прогон каждой тестовой ячейки для получения первоначальной оценки производительности.
2.  **Фаза 2: Распределение бюджета:** Общий временной бюджет интеллектуально распределяется между всеми тестовыми ячейками. Более медленным операциям выделяется больше времени для сбора достаточного количества выборок. Распределение основано на весе, обратно пропорциональном квадратному корню из времени калибровки.
3.  **Фаза 3: Измерение и коррекция:** Основной цикл измерений выполняется для каждой ячейки в соответствии с выделенным ей временным бюджетом.

#### 2.6.2. Адаптивный размер батча и учет итераций

**Решение:** Бенчмарк динамически регулирует количество итераций в батче, чтобы целевое время выполнения каждого батча было значительным (`TARGET_BATCH_MS: 300ms`).

**Обоснование:**
*   **Максимизация соотношения сигнал/шум:** Длительное выполнение батчей делает короткие случайные шумовые события статистически незначимыми.
*   **Корректность:** Количество итераций, использованное для *каждого конкретного батча*, записывается. Итоговое время на одну операцию вычисляется путем деления длительности каждого батча на соответствующее ему количество итераций, что обеспечивает статистическую точность.

#### 2.6.3. Автоматическая коррекция (Remediation)

**Решение:** Если измерение для тестовой ячейки признано нестабильным (высокая вариативность), бенчмарк автоматически перезапустит этот конкретный тест до `MAX_REMEDIATION_ATTEMPTS` раз.

**Обоснование:**
*   Это улучшает качество итогового набора данных путем самокоррекции в случае временных шумовых событий (например, внезапной фоновой задачи ОС) без вмешательства пользователя.

### 2.7. Собираемые метрики (для каждой тестовой ячейки)

Для каждой пары {алгоритм, размер} собирается подробный объект для анализа. **Основной метрикой является `momMs`**.
*   **`momMs` (Median-of-Means / Медиана средних):** Наш основной робастный показатель центральной тенденции. Он крайне устойчив к выбросам, вызванным системным шумом с «тяжелыми хвостами».
*   **`bootstrapCi95Ms` (Bootstrap доверительный интервал):** Непараметрический 95% доверительный интервал для среднего, рассчитанный на основе 2000 повторных выборок. Обеспечивает надежную оценку неопределенности.
*   **`opsPerSec`:** Операций в секунду, рассчитывается как `1000 / momMs`.
*   **`medianMs`, `iqrMs`:** Медиана и межквартильный размах для традиционного робастного статистического анализа.
*   **`coefficientOfVariation`:** Индикатор качества (`стандартное отклонение / среднее`). Низкое значение указывает на стабильное измерение.
*   `isStable`, `remediationAttempts`: Флаги, указывающие на итоговое состояние качества измерения.
*   `iterations`, `batches`: Диагностические данные о процессе измерения.
*   `calibrationTimeMs`, `timerGranularityMs`: Метаданные о среде и диагностике.

---

## 3. Структура данных и протокол сбора

### 3.1. Структура полезной нагрузки (Payload)

**Решение:** Данные отправляются в виде единого JSON-объекта, содержащего `scriptVersion`, `runId`, анонимизированные данные `env` и массив `results`. Объект `env` явно включает флаг `crossOriginIsolated: true`. Массив `perBatchMs` больше не включается в итоговые объекты `result`, так как эти данные теперь передаются потоком через `SharedArrayBuffer`.

### 3.2. Архитектура сборщика данных

**Решение:** Устаревший сборщик на базе Google Apps Script был выведен из эксплуатации. Новая архитектура использует безопасный, многоуровневый «Backend for Frontend» (BFF), построенный на платформе Cloudflare. **Cloudflare Worker** проверяет и обрабатывает входящие данные, которые затем сохраняются в SQL-базе данных **Cloudflare D1**. Эта архитектура полностью соответствует Конституции Безопасности проекта, в частности, запрету на использование секретов на стороне клиента.

---

## 4. Стратегия последующего анализа данных

Стратегия анализа разработана для использования высокоточных данных с низким уровнем шума, полученных с помощью «лабораторной» методологии.

### 4.1. Предварительная обработка и фильтрация данных

1.  **Фильтрация по версии:** Анализ будет проводиться только по данным с корректной `scriptVersion`.
2.  **Фильтрация по качеству:** Несмотря на коррекцию на стороне клиента, на сервере для тонкой фильтрации будут использоваться флаг `isStable` и метрика `coefficientOfVariation`.
3.  **Дедупликация:** `runId` и `anonId` будут использоваться для управления дубликатами.

### 4.2. Описательная и инференциальная статистика

*   **Основные показатели:** **Медиана средних (`momMs`)** и **Bootstrap доверительный интервал (`bootstrapCi95Ms`)** будут основными метриками для представления центральной тенденции и разброса.
*   **Проверка гипотез:** **Линейная смешанная модель (Linear Mixed-Effects Model)** будет основным инструментом для проверки гипотез. Этот метод позволяет учесть вложенную структуру данных (несколько измерений на одного пользователя) и контролировать смешивающиеся переменные.
    *   **Зависимая переменная:** `log(opsPersec)` будет использоваться для стабилизации дисперсии и моделирования мультипликативных эффектов.
    *   **Фиксированные эффекты:** `algorithm`, `size`, `browserEngine`, `os`, `hardwareConcurrency` и др.
    *   **Случайный эффект:** `anonId` будет включен как случайный эффект (random intercept) для учета базовых различий в производительности между отдельными участниками.
